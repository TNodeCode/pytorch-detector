{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3248bd5e-8d4f-46fd-9377-b3a345f8b32e",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e46f445-f126-455f-b736-7a0d2cc814d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\tilof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from faster_rcnn import FasterRCNNV2Detector\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba6bf60-055f-4824-9b6e-193ab9f0e434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"C:\\\\Users\\\\tilof\\\\PycharmProjects\\\\DeepLearningProjects\\\\DETR\\\\data\\\\spine\"\n",
    "train_data_dir = f\"{root_dir}\\\\train2017\"\n",
    "train_annotation_file = f\"{root_dir}\\\\annotations\\\\instances_train2017.json\"\n",
    "val_data_dir = f\"{root_dir}\\\\val2017\"\n",
    "val_annotation_file = f\"{root_dir}\\\\annotations\\\\instances_val2017.json\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.ToDtype(torch.float32),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba89f86-d037-400d-9bb1-e508584c9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = FasterRCNNV2Detector(\n",
    "    num_classes=1,\n",
    "    device=device,\n",
    "    root_dir=root_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6424fba9-792f-4732-9984-9229d647960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Start training ...\n",
      "Epoch 1/300: Epoch 1/300: loss=44.774819165468216, loss_classifier=12.943378813564777, loss_objectness=6.917764520272613, loss_box_reg=22.41640904918313, loss_rpn_box_reg=2.4972662813961506, train_map50=0.28671640157699585, train_mAP50_95=0.09614499658346176, val_map50=0.3201592266559601, val_mAP50_95=0.1276649534702301\n",
      "Epoch 2/300: Epoch 2/300: loss=38.173258513212204, loss_classifier=10.472447380423546, loss_objectness=1.819358623586595, loss_box_reg=24.096389144659042, loss_rpn_box_reg=1.7850633999332786, train_map50=0.3384534418582916, train_mAP50_95=0.12138579785823822, val_map50=0.36838608980178833, val_mAP50_95=0.1255338340997696\n",
      "Epoch 3/300: Epoch 3/300: loss=35.317369878292084, loss_classifier=9.426434978842735, loss_objectness=1.2150737419724464, loss_box_reg=23.064405009150505, loss_rpn_box_reg=1.6114559904672205, train_map50=0.5385575294494629, train_mAP50_95=0.18595537543296814, val_map50=0.36640670895576477, val_mAP50_95=0.11722265928983688\n",
      "Epoch 4/300: Epoch 4/300: loss=32.79784491658211, loss_classifier=8.263332568109035, loss_objectness=0.8869631192646921, loss_box_reg=22.15506947040558, loss_rpn_box_reg=1.4924796586856246, train_map50=0.4928774833679199, train_mAP50_95=0.2497757375240326, val_map50=0.37521106004714966, val_mAP50_95=0.16588270664215088\n",
      "Epoch 5/300: Epoch 5/300: loss=30.123103231191635, loss_classifier=7.497130811214447, loss_objectness=0.6981394882313907, loss_box_reg=20.565129965543747, loss_rpn_box_reg=1.3627030309289694, train_map50=0.5741285085678101, train_mAP50_95=0.26097342371940613, val_map50=0.32993966341018677, val_mAP50_95=0.11060847342014313\n",
      "Epoch 6/300: Epoch 6/300: loss=27.75063732266426, loss_classifier=6.722770094871521, loss_objectness=0.6016956144012511, loss_box_reg=19.166128128767014, loss_rpn_box_reg=1.2600436857901514, train_map50=0.5739583373069763, train_mAP50_95=0.35115763545036316, val_map50=0.525365948677063, val_mAP50_95=0.2211855947971344\n",
      "Epoch 7/300: Epoch 7/300: loss=25.880479991436005, loss_classifier=6.355929814279079, loss_objectness=0.5442264864686877, loss_box_reg=17.799632519483566, loss_rpn_box_reg=1.1806911574676633, train_map50=0.5333333611488342, train_mAP50_95=0.3175446391105652, val_map50=0.561945378780365, val_mAP50_95=0.20983856916427612\n",
      "Epoch 8/300: Epoch 8/300: loss=23.54095160961151, loss_classifier=5.537136182188988, loss_objectness=0.41438974835909903, loss_box_reg=16.48497001826763, loss_rpn_box_reg=1.1044556247070432, train_map50=0.8218899965286255, train_mAP50_95=0.5257564187049866, val_map50=0.5033847093582153, val_mAP50_95=0.21279287338256836\n",
      "Epoch 9/300: Epoch 9/300: loss=21.71050277352333, loss_classifier=5.045473448932171, loss_objectness=0.3408456325996667, loss_box_reg=15.327075645327568, loss_rpn_box_reg=0.9971081553958356, train_map50=0.8001435995101929, train_mAP50_95=0.5322043299674988, val_map50=0.32395368814468384, val_mAP50_95=0.1309541016817093\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FasterRCNNV2Detector' object has no attribute 'lr_scheduler'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_step_every\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_annotation_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_annotation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_data_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_data_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_annotation_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_annotation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_transforms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_annotation_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_transforms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\DeepLearningProjects\\MasterThesis\\ObjectDetection\\faster_rcnn.py:174\u001b[0m, in \u001b[0;36mFasterRCNNV2Detector.train\u001b[1;34m(self, n_epochs, lr, batch_size, start_epoch, resume, save_every, lr_step_every, num_classes, device, train_data_dir, train_annotation_file, train_transforms, val_data_dir, val_annotation_file, val_transforms, val_batch_size, test_data_dir, test_annotation_file, test_transforms, test_batch_size)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Update learning rate\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m lr_step_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# Validate model\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_dataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# Put model into evaluation mode\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FasterRCNNV2Detector' object has no attribute 'lr_scheduler'"
     ]
    }
   ],
   "source": [
    "detector.train(\n",
    "    n_epochs = 300,\n",
    "    lr = 5e-3,\n",
    "    batch_size = 16,\n",
    "    start_epoch = 10,\n",
    "    resume = None,\n",
    "    save_every = 10,\n",
    "    lr_step_every = 10,\n",
    "    num_classes = 1,\n",
    "    device=device,\n",
    "    train_data_dir = train_data_dir,\n",
    "    train_annotation_file = train_annotation_file,\n",
    "    train_transforms = transforms,\n",
    "    val_data_dir = val_data_dir,\n",
    "    val_annotation_file = val_annotation_file,\n",
    "    val_transforms = transforms,\n",
    "    test_data_dir = None,\n",
    "    test_annotation_file = None,\n",
    "    test_transforms = None,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249a411-c3ad-4f37-9084-dc5ec08d022f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
